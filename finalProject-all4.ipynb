{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/6w09q22n4f73ds9jwmgbstjc0000gn/T/ipykernel_79456/2046904662.py:3: DtypeWarning: Columns (45,179,180,182,183,189,190,193,194,197,198,203,204,205,206,209,210,213,214,218,219,220,222,224,226,233,234,235,236,237,238,248,249,253,254,255,260,262,263,266,267,268,269,283,284,294,295,301) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data_file.csv') # pandas data frame\n"
     ]
    }
   ],
   "source": [
    "##get data\n",
    "##data is already from 2012-2020\n",
    "data = pd.read_csv('data_file.csv') # pandas data frame\n",
    "\n",
    "\n",
    "##preprocessing\n",
    "\n",
    "\n",
    "##removes \n",
    "data = data.loc[(data['desc'].str.startswith('('))]\n",
    "data = data[data['play_type'] != 'qb_kneel']\n",
    "data = data[data['play_type'] != 'no_play']\n",
    "data = data.dropna(subset=['down'])\n",
    "data = data.dropna(subset=['play_type'])\n",
    "data = data.dropna(subset=['wp'])\n",
    "data = data[(data['play_type'] == 'pass') | (data['play_type'] == 'run') | (data['play_type'] == 'field_goal') | (data['play_type'] == 'punt')]\n",
    "# Look into creating specific year and months, and training and testing on specific years/gmaes. \n",
    "\n",
    "\n",
    "# Extract year and month using string slicing\n",
    "data['year'] = data['game_id'].str[:4].astype(int)\n",
    "data['month'] = data['game_id'].str[5:7].astype(int)\n",
    "\n",
    "\n",
    "# Create a new 'date' column with the 1st day of each extracted year and month\n",
    "\n",
    "\n",
    "# Come back to this when we want to specify split spots  \n",
    "# def parse_date(x):\n",
    "#     parts = x.split('_')\n",
    "#     year = int(parts[0])\n",
    "#     month = int(parts[1])\n",
    "#     print(month)\n",
    "#     return pd.Timestamp(year=int(year), month=month), day=1)\n",
    "\n",
    "# Apply the function to the 'game_date' column\n",
    "# data['date'] = data['game_id'].apply(parse_date)\n",
    "# # Now you can sort by this 'date' column if needed\n",
    "# data.sort_values(by='date', inplace=True)\n",
    "\n",
    "# # And use the 'date' column for splitting your data, work with in the future to pick specific dates \n",
    "# #Right now not working because the months in the game_id are 01-12, when for pd.TimeStamp they need to be in 1-12. \n",
    "# split_date = pd.Timestamp(year=2018, month=12, day=1)  # Replace YYYY and MM with your split year and month\n",
    "# train_data = data[data['date'] < split_date]\n",
    "# test_data = data[data['date'] >= split_date]\n",
    "\n",
    " \n",
    "##fixes playtype to be strictly pass or run \n",
    "##lables scrambles as passes\n",
    "data.loc[data['pass']==1,'play_type'] = 'pass'\n",
    "data.loc[data.rush==1,'play_type'] = 'run'\n",
    "\n",
    "# columns are the strings \n",
    "# things to encode from strings to 1s and zeros\n",
    "# season_type, \n",
    "columnsKeep = ['game_id', 'year','month','season_type','week','posteam','posteam_type','defteam','side_of_field','yardline_100','half_seconds_remaining','home_team','away_team',\n",
    "               'game_seconds_remaining','game_half','drive','down','time','yrdln','ydstogo','desc','play_type','yards_gained','shotgun','no_huddle','qb_dropback','qb_kneel',\n",
    "               'qb_spike','qb_scramble','pass_length','run_location','run_gap','home_timeouts_remaining','away_timeouts_remaining','total_home_score','total_away_score',\n",
    "               'passer_player_name','receiver_player_name','rusher_player_name','play_type_nfl','roof','surface','temp','wind','home_coach','away_coach','game_stadium',\n",
    "               'success', 'wp']\n",
    "\n",
    "data = data[columnsKeep]\n",
    "\n",
    "# print(data.head(5))\n",
    "\n",
    "data.to_csv('finalized_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334503\n",
      "Number of 'run' plays: 117123\n",
      "Number of 'pass' plays: 186390\n",
      "Number of 'fg' plays: 9285\n",
      "Number of 'punt' plays: 21705\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "\n",
    "# Count occurrences of each play type\n",
    "runCount = (data['play_type'] == 'run').sum()\n",
    "passCount = (data['play_type'] == 'pass').sum()\n",
    "fgCount = (data['play_type'] == 'field_goal').sum()\n",
    "puntCount = (data['play_type'] == 'punt').sum()\n",
    "\n",
    "\n",
    "print(\"Number of 'run' plays:\", runCount)\n",
    "print(\"Number of 'pass' plays:\", passCount)\n",
    "print(\"Number of 'fg' plays:\", fgCount)\n",
    "print(\"Number of 'punt' plays:\", puntCount)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in selected features:\n",
      "down                      0\n",
      "drive                     0\n",
      "ydstogo                   0\n",
      "yardline_100              0\n",
      "half_seconds_remaining    0\n",
      "game_seconds_remaining    0\n",
      "wp                        0\n",
      "week                      0\n",
      "yards_gained              0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in target (play_type): 0\n"
     ]
    }
   ],
   "source": [
    "##check for nan values in data\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isnull(row['play_type']):  # Check if the value in the 'down' column is NaN\n",
    "        print(row['desc'])  # Print the value in the 'desc' column if 'down' is NaN\n",
    "\n",
    "# wind and stadium had a lot of null \n",
    "## check for missing values in data\n",
    "selected_features = ['down', 'drive', 'ydstogo', 'yardline_100', 'half_seconds_remaining', 'game_seconds_remaining','wp','week','yards_gained']\n",
    "missing_values_features = data[selected_features].isnull().sum()\n",
    "print(\"Missing values in selected features:\")\n",
    "print(missing_values_features)\n",
    "\n",
    "# Check for missing values in the target\n",
    "missing_values_target = data['play_type'].isnull().sum()\n",
    "print(\"\\nMissing values in target (play_type):\", missing_values_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = data[['down','drive', 'ydstogo','yardline_100', 'half_seconds_remaining', 'game_seconds_remaining', 'wp']]\n",
    "target = data['play_type'].map({'pass': 0, 'run': 1, 'field_goal':2,'punt':3})\n",
    "\n",
    "# Initialize the scaler \n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Fit the scaler on the features and transform them \n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Reshaping input data for LSTM [samples, time steps, features]\n",
    "# Here, we assume each sample is a single time step\n",
    "features_scaled = features_scaled.reshape((features_scaled.shape[0], 1, features_scaled.shape[1]))\n",
    "\n",
    "# Talk to Nicolai and Ulrich if they think this is a good idea to split it up into drives as our time stamp. \n",
    "# 1 indicates that each sample consists of 1 timestep. This is a key detail: \n",
    "# it means you are treating each play as a separate, single-timestep sequence. T\n",
    "# This is a simplification, as ideally, plays within a single drive might be treated as sequences to capture their temporal dependencies.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, shuffle = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(target.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 19:21:09.214228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:09.214708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:09.215279: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-12 19:21:09.275799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:09.276184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:09.276608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-12 19:21:09.371608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:09.372231: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:09.372642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-12 19:21:09.442012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:09.442781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:09.443309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-12 19:21:09.686702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:09.687385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:09.688057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-12 19:21:09.756676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:09.757119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:09.757510: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3744/3764 [============================>.] - ETA: 0s - loss: 0.5828 - accuracy: 0.6952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 19:21:13.688951: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:13.689484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:13.690105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-12 19:21:13.751234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:13.751657: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:13.752036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3764/3764 [==============================] - 5s 980us/step - loss: 0.5826 - accuracy: 0.6953 - val_loss: 0.5435 - val_accuracy: 0.7112\n",
      "Epoch 2/10\n",
      "3764/3764 [==============================] - 3s 930us/step - loss: 0.5339 - accuracy: 0.7128 - val_loss: 0.5260 - val_accuracy: 0.7193\n",
      "Epoch 3/10\n",
      "3764/3764 [==============================] - 3s 918us/step - loss: 0.5256 - accuracy: 0.7178 - val_loss: 0.5245 - val_accuracy: 0.7164\n",
      "Epoch 4/10\n",
      "3764/3764 [==============================] - 3s 928us/step - loss: 0.5224 - accuracy: 0.7190 - val_loss: 0.5191 - val_accuracy: 0.7228\n",
      "Epoch 5/10\n",
      "3764/3764 [==============================] - 3s 919us/step - loss: 0.5195 - accuracy: 0.7207 - val_loss: 0.5196 - val_accuracy: 0.7216\n",
      "Epoch 6/10\n",
      "3764/3764 [==============================] - 3s 919us/step - loss: 0.5180 - accuracy: 0.7222 - val_loss: 0.5193 - val_accuracy: 0.7205\n",
      "Epoch 7/10\n",
      "3764/3764 [==============================] - 3s 918us/step - loss: 0.5166 - accuracy: 0.7222 - val_loss: 0.5166 - val_accuracy: 0.7235\n",
      "Epoch 8/10\n",
      "3764/3764 [==============================] - 3s 918us/step - loss: 0.5149 - accuracy: 0.7228 - val_loss: 0.5147 - val_accuracy: 0.7226\n",
      "Epoch 9/10\n",
      "3764/3764 [==============================] - 3s 922us/step - loss: 0.5139 - accuracy: 0.7232 - val_loss: 0.5119 - val_accuracy: 0.7253\n",
      "Epoch 10/10\n",
      "3764/3764 [==============================] - 4s 958us/step - loss: 0.5129 - accuracy: 0.7231 - val_loss: 0.5124 - val_accuracy: 0.7235\n",
      "2091/2091 [==============================] - 1s 318us/step - loss: 0.5204 - accuracy: 0.7232\n",
      "Test Accuracy: 0.723, Test Loss: 0.520\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32,return_sequences=False),\n",
    "    Dense(4, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.3f}, Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2091 [..............................] - ETA: 8:55"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 19:21:54.904406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:54.904997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:54.905696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-12 19:21:54.967702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-12 19:21:54.968117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-12 19:21:54.968512: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2091/2091 [==============================] - 1s 297us/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75     37737\n",
      "           1       0.61      0.67      0.64     23520\n",
      "           2       0.84      0.87      0.85      1858\n",
      "           3       0.91      0.98      0.95      3786\n",
      "\n",
      "    accuracy                           0.72     66901\n",
      "   macro avg       0.78      0.81      0.80     66901\n",
      "weighted avg       0.73      0.72      0.72     66901\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27386  9964   196   191]\n",
      " [ 7629 15657   104   130]\n",
      " [  183    34  1614    27]\n",
      " [   41     3    17  3725]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predicted_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267602\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Shape of X_train: (267602, 1, 7)\n"
     ]
    }
   ],
   "source": [
    "# length of X train, and nulls in the x,train, x_test, y_train, y_test \n",
    "print(len(X_train))\n",
    "nan_indices_X = np.isnan(X_train)\n",
    "nan_count_X = np.sum(nan_indices_X)\n",
    "print(nan_count_X)\n",
    "\n",
    "nan_indices_X_test = np.isnan(X_test)\n",
    "nan_count_X_test = np.sum(nan_indices_X_test)\n",
    "print(nan_count_X_test)\n",
    "\n",
    "nan_indices_y = np.isnan(y_train)\n",
    "nan_count_y = np.sum(nan_indices_y)\n",
    "print(nan_count_y)\n",
    "\n",
    "nan_indices_Y_test = np.isnan(y_test)\n",
    "nan_count_Y_test = np.sum(nan_indices_Y_test)\n",
    "print(nan_count_Y_test)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArtificialIntelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
