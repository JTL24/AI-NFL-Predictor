{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ys/6w09q22n4f73ds9jwmgbstjc0000gn/T/ipykernel_1610/2046904662.py:3: DtypeWarning: Columns (45,179,180,182,183,189,190,193,194,197,198,203,204,205,206,209,210,213,214,218,219,220,222,224,226,233,234,235,236,237,238,248,249,253,254,255,260,262,263,266,267,268,269,283,284,294,295,301) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('data_file.csv') # pandas data frame\n"
     ]
    }
   ],
   "source": [
    "##get data\n",
    "##data is already from 2012-2020\n",
    "data = pd.read_csv('data_file.csv') # pandas data frame\n",
    "\n",
    "\n",
    "##preprocessing\n",
    "\n",
    "\n",
    "##removes \n",
    "data = data.loc[(data['desc'].str.startswith('('))]\n",
    "data = data[data['play_type'] != 'qb_kneel']\n",
    "data = data[data['play_type'] != 'no_play']\n",
    "data = data.dropna(subset=['down'])\n",
    "data = data.dropna(subset=['play_type'])\n",
    "data = data.dropna(subset=['wp'])\n",
    "data = data[(data['play_type'] == 'pass') | (data['play_type'] == 'run') | (data['play_type'] == 'field_goal') | (data['play_type'] == 'punt')]\n",
    "# Look into creating specific year and months, and training and testing on specific years/gmaes. \n",
    "\n",
    "\n",
    "# Extract year and month using string slicing\n",
    "data['year'] = data['game_id'].str[:4].astype(int)\n",
    "data['month'] = data['game_id'].str[5:7].astype(int)\n",
    "\n",
    "\n",
    "# Create a new 'date' column with the 1st day of each extracted year and month\n",
    "\n",
    "\n",
    "# Come back to this when we want to specify split spots  \n",
    "# def parse_date(x):\n",
    "#     parts = x.split('_')\n",
    "#     year = int(parts[0])\n",
    "#     month = int(parts[1])\n",
    "#     print(month)\n",
    "#     return pd.Timestamp(year=int(year), month=month), day=1)\n",
    "\n",
    "# Apply the function to the 'game_date' column\n",
    "# data['date'] = data['game_id'].apply(parse_date)\n",
    "# # Now you can sort by this 'date' column if needed\n",
    "# data.sort_values(by='date', inplace=True)\n",
    "\n",
    "# # And use the 'date' column for splitting your data, work with in the future to pick specific dates \n",
    "# #Right now not working because the months in the game_id are 01-12, when for pd.TimeStamp they need to be in 1-12. \n",
    "# split_date = pd.Timestamp(year=2018, month=12, day=1)  # Replace YYYY and MM with your split year and month\n",
    "# train_data = data[data['date'] < split_date]\n",
    "# test_data = data[data['date'] >= split_date]\n",
    "\n",
    " \n",
    "##fixes playtype to be strictly pass or run \n",
    "##lables scrambles as passes\n",
    "data.loc[data['pass']==1,'play_type'] = 'pass'\n",
    "data.loc[data.rush==1,'play_type'] = 'run'\n",
    "\n",
    "# columns are the strings \n",
    "# things to encode from strings to 1s and zeros\n",
    "# season_type, \n",
    "columnsKeep = ['game_id', 'year','month','season_type','week','posteam','posteam_type','defteam','side_of_field','yardline_100','half_seconds_remaining','home_team','away_team',\n",
    "               'game_seconds_remaining','game_half','drive','down','time','yrdln','ydstogo','desc','play_type','yards_gained','shotgun','no_huddle','qb_dropback','qb_kneel',\n",
    "               'qb_spike','qb_scramble','pass_length','run_location','run_gap','home_timeouts_remaining','away_timeouts_remaining','total_home_score','total_away_score',\n",
    "               'passer_player_name','receiver_player_name','rusher_player_name','play_type_nfl','roof','surface','temp','wind','home_coach','away_coach','game_stadium',\n",
    "               'success', 'wp']\n",
    "\n",
    "data = data[columnsKeep]\n",
    "\n",
    "# print(data.head(5))\n",
    "\n",
    "data.to_csv('finalized_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334503\n",
      "Number of 'run' plays: 117123\n",
      "Number of 'pass' plays: 186390\n",
      "Number of 'fg' plays: 9285\n",
      "Number of 'punt' plays: 21705\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "\n",
    "# Count occurrences of each play type\n",
    "runCount = (data['play_type'] == 'run').sum()\n",
    "passCount = (data['play_type'] == 'pass').sum()\n",
    "fgCount = (data['play_type'] == 'field_goal').sum()\n",
    "puntCount = (data['play_type'] == 'punt').sum()\n",
    "\n",
    "\n",
    "print(\"Number of 'run' plays:\", runCount)\n",
    "print(\"Number of 'pass' plays:\", passCount)\n",
    "print(\"Number of 'fg' plays:\", fgCount)\n",
    "print(\"Number of 'punt' plays:\", puntCount)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in selected features:\n",
      "down                      0\n",
      "drive                     0\n",
      "ydstogo                   0\n",
      "yardline_100              0\n",
      "half_seconds_remaining    0\n",
      "game_seconds_remaining    0\n",
      "wp                        0\n",
      "week                      0\n",
      "yards_gained              0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in target (play_type): 0\n"
     ]
    }
   ],
   "source": [
    "##check for nan values in data\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isnull(row['play_type']):  # Check if the value in the 'down' column is NaN\n",
    "        print(row['desc'])  # Print the value in the 'desc' column if 'down' is NaN\n",
    "\n",
    "# wind and stadium had a lot of null \n",
    "## check for missing values in data\n",
    "selected_features = ['down', 'drive', 'ydstogo', 'yardline_100', 'half_seconds_remaining', 'game_seconds_remaining','wp','week','yards_gained']\n",
    "missing_values_features = data[selected_features].isnull().sum()\n",
    "print(\"Missing values in selected features:\")\n",
    "print(missing_values_features)\n",
    "\n",
    "# Check for missing values in the target\n",
    "missing_values_target = data['play_type'].isnull().sum()\n",
    "print(\"\\nMissing values in target (play_type):\", missing_values_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = data[['down','drive', 'ydstogo','yardline_100', 'half_seconds_remaining', 'game_seconds_remaining', 'wp']]\n",
    "target = data['play_type'].map({'pass': 0, 'run': 1, 'field_goal':2,'punt':3})\n",
    "\n",
    "# Initialize the scaler \n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Fit the scaler on the features and transform them \n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Reshaping input data for LSTM [samples, time steps, features]\n",
    "# Here, we assume each sample is a single time step\n",
    "features_scaled = features_scaled.reshape((features_scaled.shape[0], 1, features_scaled.shape[1]))\n",
    "\n",
    "# Talk to Nicolai and Ulrich if they think this is a good idea to split it up into drives as our time stamp. \n",
    "# 1 indicates that each sample consists of 1 timestep. This is a key detail: \n",
    "# it means you are treating each play as a separate, single-timestep sequence. T\n",
    "# This is a simplification, as ideally, plays within a single drive might be treated as sequences to capture their temporal dependencies.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, shuffle = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(target.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:52:18.550924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:18.552044: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:18.552383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-23 12:52:18.605895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:18.606283: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:18.606733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-23 12:52:18.642345: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-04-23 12:52:18.739478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:18.740090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:18.740575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-23 12:52:18.805028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:18.805726: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:18.806200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-23 12:52:19.053143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:19.053853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:19.054275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-23 12:52:19.110262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:19.110820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:19.111281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3717/3764 [============================>.] - ETA: 0s - loss: 0.5854 - accuracy: 0.6973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:52:23.056192: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:23.056855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:23.057267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-23 12:52:23.115153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:23.115580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:23.115961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3764/3764 [==============================] - 5s 988us/step - loss: 0.5848 - accuracy: 0.6974 - val_loss: 0.5413 - val_accuracy: 0.7089\n",
      "Epoch 2/10\n",
      "3764/3764 [==============================] - 4s 942us/step - loss: 0.5343 - accuracy: 0.7142 - val_loss: 0.5278 - val_accuracy: 0.7181\n",
      "Epoch 3/10\n",
      "3764/3764 [==============================] - 3s 910us/step - loss: 0.5273 - accuracy: 0.7169 - val_loss: 0.5278 - val_accuracy: 0.7182\n",
      "Epoch 4/10\n",
      "3764/3764 [==============================] - 3s 909us/step - loss: 0.5230 - accuracy: 0.7196 - val_loss: 0.5273 - val_accuracy: 0.7185\n",
      "Epoch 5/10\n",
      "3764/3764 [==============================] - 3s 907us/step - loss: 0.5204 - accuracy: 0.7208 - val_loss: 0.5190 - val_accuracy: 0.7230\n",
      "Epoch 6/10\n",
      "3764/3764 [==============================] - 4s 944us/step - loss: 0.5182 - accuracy: 0.7220 - val_loss: 0.5191 - val_accuracy: 0.7235\n",
      "Epoch 7/10\n",
      "3764/3764 [==============================] - 3s 900us/step - loss: 0.5167 - accuracy: 0.7219 - val_loss: 0.5190 - val_accuracy: 0.7214\n",
      "Epoch 8/10\n",
      "3764/3764 [==============================] - 3s 910us/step - loss: 0.5157 - accuracy: 0.7227 - val_loss: 0.5210 - val_accuracy: 0.7194\n",
      "Epoch 9/10\n",
      "3764/3764 [==============================] - 4s 946us/step - loss: 0.5143 - accuracy: 0.7235 - val_loss: 0.5147 - val_accuracy: 0.7243\n",
      "Epoch 10/10\n",
      "3764/3764 [==============================] - 4s 944us/step - loss: 0.5135 - accuracy: 0.7234 - val_loss: 0.5133 - val_accuracy: 0.7249\n",
      "2091/2091 [==============================] - 1s 317us/step - loss: 0.5204 - accuracy: 0.7233\n",
      "Test Accuracy: 0.723, Test Loss: 0.520\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32,return_sequences=False),\n",
    "    Dense(4, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.3f}, Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2091 [..............................] - ETA: 8:39"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 12:52:59.251153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:59.251750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:59.252200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-23 12:52:59.311376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-23 12:52:59.311786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-23 12:52:59.312157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2091/2091 [==============================] - 1s 293us/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76     37737\n",
      "           1       0.62      0.64      0.63     23520\n",
      "           2       0.87      0.84      0.85      1858\n",
      "           3       0.91      0.99      0.94      3786\n",
      "\n",
      "    accuracy                           0.72     66901\n",
      "   macro avg       0.79      0.80      0.79     66901\n",
      "weighted avg       0.72      0.72      0.72     66901\n",
      "\n",
      "Confusion Matrix:\n",
      "[[28101  9280   153   203]\n",
      " [ 8313 15002    68   137]\n",
      " [  210    46  1557    45]\n",
      " [   38     5    13  3730]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predicted_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data['play_type'], prefix='play_type')\n",
    "\n",
    "df = pd.concat([data, dummies], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2012_01_ATL_KC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[1;32m      9\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(corr_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10052\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  10053\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 10054\u001b[0m mat \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, na_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m  10056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  10057\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1837\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1838\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1840\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1794\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1795\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2012_01_ATL_KC'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267602\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Shape of X_train: (267602, 1, 7)\n"
     ]
    }
   ],
   "source": [
    "# length of X train, and nulls in the x,train, x_test, y_train, y_test \n",
    "print(len(X_train))\n",
    "nan_indices_X = np.isnan(X_train)\n",
    "nan_count_X = np.sum(nan_indices_X)\n",
    "print(nan_count_X)\n",
    "\n",
    "nan_indices_X_test = np.isnan(X_test)\n",
    "nan_count_X_test = np.sum(nan_indices_X_test)\n",
    "print(nan_count_X_test)\n",
    "\n",
    "nan_indices_y = np.isnan(y_train)\n",
    "nan_count_y = np.sum(nan_indices_y)\n",
    "print(nan_count_y)\n",
    "\n",
    "nan_indices_Y_test = np.isnan(y_test)\n",
    "nan_count_Y_test = np.sum(nan_indices_Y_test)\n",
    "print(nan_count_Y_test)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArtificialIntelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
